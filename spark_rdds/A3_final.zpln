{
  "paragraphs": [
    {
      "text": "%md\n# Big Data: Spark RDDs (exercises)\nObjectives:\n* Show the basic understanding of (creating) RDDs\n* Get to know what happens with partitions and partitioners in Spark\n* Work with the Shakespeare Data",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:40+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Big Data: Spark RDDs (exercises)</h1>\n<p>Objectives:</p>\n<ul>\n<li>Show the basic understanding of (creating) RDDs</li>\n<li>Get to know what happens with partitions and partitioners in Spark</li>\n<li>Work with the Shakespeare Data</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342896_533568384",
      "id": "20210323-214017_1217973860",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:40+0000",
      "dateFinished": "2022-03-20T17:58:41+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:181"
    },
    {
      "text": "%spark\n// Sanity check for Spark and Scala\nprintf(\"Spark %s\\nScala %s\", sc.version, util.Properties.versionString)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:41:36+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Spark 3.1.1\nScala version 2.12.10"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_1817241425",
      "id": "paragraph_1631794243863_294069186",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:41:36+0000",
      "dateFinished": "2022-03-20T19:41:36+0000",
      "status": "FINISHED",
      "$$hashKey": "object:182"
    },
    {
      "text": "%md\n## Exercise 1.1\nCheck the Spark RDD programming guide,\n\n* https://spark.apache.org/docs/3.1.1/rdd-programming-guide.html\n\nand answer the following questions (in 1-3 sentences):\n\na. What is an RDD?\nb. Explain the differences between transformations and actions.\nc. Give two example transformations where shuffling the data is needed.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:51+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Exercise 1.1</h2>\n<p>Check the Spark RDD programming guide,</p>\n<ul>\n<li><a href=\"https://spark.apache.org/docs/3.1.1/rdd-programming-guide.html\">https://spark.apache.org/docs/3.1.1/rdd-programming-guide.html</a></li>\n</ul>\n<p>and answer the following questions (in 1-3 sentences):</p>\n<p>a. What is an RDD?<br />\nb. Explain the differences between transformations and actions.<br />\nc. Give two example transformations where shuffling the data is needed.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_248455545",
      "id": "paragraph_1638911853147_1545900617",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:51+0000",
      "dateFinished": "2022-03-20T17:58:51+0000",
      "status": "FINISHED",
      "$$hashKey": "object:183"
    },
    {
      "text": "%md\na. RDD is the most basic abstraction in Spark. It is a read-only, partitioned, fault-tolerant collection of records that can be operated in parallel.\nb. Transformation creates a new RDD but does not have to materialize it. Action runs a computation and materializes the RDD.\nc. groupByKey() and reduceByKey()",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:51+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>a. RDD is the most basic abstraction in Spark. It is a read-only, partitioned, fault-tolerant collection of records that can be operated in parallel.<br />\nb. Transformation creates a new RDD but does not have to materialize it. Action runs a computation and materializes the RDD.<br />\nc. groupByKey() and reduceByKey()</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647735451317_932150256",
      "id": "paragraph_1647735451317_932150256",
      "dateCreated": "2022-03-20T00:17:31+0000",
      "dateStarted": "2022-03-20T17:58:51+0000",
      "dateFinished": "2022-03-20T17:58:51+0000",
      "status": "FINISHED",
      "$$hashKey": "object:184"
    },
    {
      "text": "%md\n## Exercise 1.2\na. Give the line of code for creating an RDD using the `parallelize()` operation with the numbers 0 to 799 in it. We want this RDD to be split up in 8 different partitions.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:51+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Exercise 1.2</h2>\n<p>a. Give the line of code for creating an RDD using the <code>parallelize()</code> operation with the numbers 0 to 799 in it. We want this RDD to be split up in 8 different partitions.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_300919100",
      "id": "paragraph_1631794220150_1011381899",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:51+0000",
      "dateFinished": "2022-03-20T17:58:51+0000",
      "status": "FINISHED",
      "$$hashKey": "object:185"
    },
    {
      "text": "%spark\nval rdd = sc.parallelize(0 to 799, 8)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:51+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mrdd\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[Int]\u001b[0m = ParallelCollectionRDD[0] at parallelize at <console>:26\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_441679664",
      "id": "paragraph_1631794251921_1962384498",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:51+0000",
      "dateFinished": "2022-03-20T17:58:52+0000",
      "status": "FINISHED",
      "$$hashKey": "object:186"
    },
    {
      "text": "%md\nb. If we execute the line of code from answer a, what will happen?",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:52+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>b. If we execute the line of code from answer a, what will happen?</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_359702094",
      "id": "paragraph_1644578073323_1894678196",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:52+0000",
      "dateFinished": "2022-03-20T17:58:52+0000",
      "status": "FINISHED",
      "$$hashKey": "object:187"
    },
    {
      "text": "%md\nAnswer: A Seq collection (0-799) will be created in memory. Then the elements of this collection will copied to create the RDD with 8 partitions",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:52+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Answer: A Seq collection (0-799) will be created in memory. Then the elements of this collection will copied to create the RDD with 8 partitions</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647736032197_2003737120",
      "id": "paragraph_1647736032197_2003737120",
      "dateCreated": "2022-03-20T00:27:12+0000",
      "dateStarted": "2022-03-20T17:58:52+0000",
      "dateFinished": "2022-03-20T17:58:52+0000",
      "status": "FINISHED",
      "$$hashKey": "object:188"
    },
    {
      "text": "%md\nWe now execute the following line of code:",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:52+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>We now execute the following line of code:</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_374380399",
      "id": "paragraph_1631794274564_1276090416",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:52+0000",
      "dateFinished": "2022-03-20T17:58:52+0000",
      "status": "FINISHED",
      "$$hashKey": "object:189"
    },
    {
      "text": "%spark\nval sample = rdd.takeSample(false,8)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:52+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34msample\u001b[0m: \u001b[1m\u001b[32mArray[Int]\u001b[0m = Array(209, 524, 168, 717, 653, 372, 340, 432)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=0",
              "$$hashKey": "object:2155"
            },
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=1",
              "$$hashKey": "object:2156"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_8054840",
      "id": "paragraph_1631794284910_1878093945",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:52+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:190"
    },
    {
      "text": "%md\nc. What do the parameters ‘false’ and ‘8’ mean?\nd. After executing the code block above, look at the [stages](http://localhost:4040/stages/). Why did Spark fire off eight different tasks?\ne. (optional/advanced) Why would Spark create two jobs to take the sample? _Hint: read the [code on takeSample()](https://github.com/apache/spark/blob/1d550c4e90275ab418b9161925049239227f3dc9/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L620)._",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:53+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>c. What do the parameters ‘false’ and ‘8’ mean?<br />\nd. After executing the code block above, look at the <a href=\"http://localhost:4040/stages/\">stages</a>. Why did Spark fire off eight different tasks?<br />\ne. (optional/advanced) Why would Spark create two jobs to take the sample? <em>Hint: read the <a href=\"https://github.com/apache/spark/blob/1d550c4e90275ab418b9161925049239227f3dc9/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L620\">code on takeSample()</a>.</em></p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_1962053397",
      "id": "paragraph_1631794296169_1420267951",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:53+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:191"
    },
    {
      "text": "%md\nc. 'false' means no replacement. '8' means take 8 random number from rdd.\nd. Because we indicate 8 partitioner for the RDD, so by default Spark will alocate one task for each partitioner.\ne. Inside takeSampe, count() and collect() are called several times. Therefore, the dataset rdd needs to be materialized first. ",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:53+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>c. &lsquo;false&rsquo; means no replacement. &lsquo;8&rsquo; means take 8 random number from rdd.<br />\nd. Because we indicate 8 partitioner for the RDD, so by default Spark will alocate one task for each partitioner.<br />\ne. Inside takeSampe, count() and collect() are called several times. Therefore, the dataset rdd needs to be materialized first.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647737016214_2142243018",
      "id": "paragraph_1647737016214_2142243018",
      "dateCreated": "2022-03-20T00:43:36+0000",
      "dateStarted": "2022-03-20T17:58:53+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:192"
    },
    {
      "text": "%md \n## Exercise 1.3\n(In one or a couple of sentences:)\na. Describe what the functions `flatmap()` and `map()` do and its differences.\nb. Describe what the functions `take()` and `collect()` do and what can be hazardous in using `collect()`.\nc. Describe what `cache()` does and what can be hazardous about it.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:53+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Exercise 1.3</h2>\n<p>(In one or a couple of sentences:)<br />\na. Describe what the functions <code>flatmap()</code> and <code>map()</code> do and its differences.<br />\nb. Describe what the functions <code>take()</code> and <code>collect()</code> do and what can be hazardous in using <code>collect()</code>.<br />\nc. Describe what <code>cache()</code> does and what can be hazardous about it.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_2073593923",
      "id": "paragraph_1631794330892_289632298",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:53+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:193"
    },
    {
      "text": "%md\na. map() would return a new distributed dataset by passing each element of the source through a defined function. flatMap() is similar to map(), but each input item can be mapped to 0 or more output items.\nb. take(n) would return the first n elements of the dataset, collect() would return all the elements of a dataset. When memory is not big enough to accomodate the dataset, collect() will lead to problems. \nc. When an RDD is first materialized, cache() will keep this RDD in memory for further computation. Abusing cache() can consume a lot of memory and leave little memory left for other RDDs or tasks.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:53+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>a. map() would return a new distributed dataset by passing each element of the source through a defined function. flatMap() is similar to map(), but each input item can be mapped to 0 or more output items.<br />\nb. take(n) would return the first n elements of the dataset, collect() would return all the elements of a dataset. When memory is not big enough to accomodate the dataset, collect() will lead to problems.<br />\nc. When an RDD is first materialized, cache() will keep this RDD in memory for further computation. Abusing cache() can consume a lot of memory and leave little memory left for other RDDs or tasks.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647737835379_1403505281",
      "id": "paragraph_1647737835379_1403505281",
      "dateCreated": "2022-03-20T00:57:15+0000",
      "dateStarted": "2022-03-20T17:58:53+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:194"
    },
    {
      "text": "%md\n## Exercise 2.1\na. For each value, write down the number of partitions, whether there is a partitioner assigned to and if so, which one. Also, briefly indicate how you got the answer.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:59:37+0000",
      "progress": 0,
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Exercise 2.1</h2>\n<p>a. For each value, write down the number of partitions, whether there is a partitioner assigned to and if so, which one. Also, briefly indicate how you got the answer.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_1587942780",
      "id": "paragraph_1631197722812_724425735",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:53+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:195"
    },
    {
      "text": "%spark\nval A = sc.parallelize(0 to 999,8)\nA.take(20)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:53+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mA\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[Int]\u001b[0m = ParallelCollectionRDD[2] at parallelize at <console>:26\n\u001b[1m\u001b[34mres2\u001b[0m: \u001b[1m\u001b[32mArray[Int]\u001b[0m = Array(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=2",
              "$$hashKey": "object:2406"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_65094985",
      "id": "20210323-214017_1526376678",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:53+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:196"
    },
    {
      "text": "%md\nAnswer: There are 8 partitions, and no partitioner. There are 4 cores on my computer, but each core can run 2 threads. I think that's the reason the default number of partitions is 8.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:53+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Answer: There are 8 partitions, and no partitioner. There are 4 cores on my computer, but each core can run 2 threads. I think that&rsquo;s the reason the default number of partitions is 8.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647738199308_427981767",
      "id": "paragraph_1647738199308_427981767",
      "dateCreated": "2022-03-20T01:03:19+0000",
      "dateStarted": "2022-03-20T17:58:53+0000",
      "dateFinished": "2022-03-20T17:58:53+0000",
      "status": "FINISHED",
      "$$hashKey": "object:197"
    },
    {
      "text": "%spark\nval B = A.map(x => (x % 100, 1000 - x))\nB.take(20)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:54+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mB\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Int)]\u001b[0m = MapPartitionsRDD[3] at map at <console>:26\n\u001b[1m\u001b[34mres3\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Int)]\u001b[0m = Array((0,1000), (1,999), (2,998), (3,997), (4,996), (5,995), (6,994), (7,993), (8,992), (9,991), (10,990), (11,989), (12,988), (13,987), (14,986), (15,985), (16,984), (17,983), (18,982), (19,981))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=3",
              "$$hashKey": "object:2492"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_1910549762",
      "id": "20210323-214017_753817829",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:54+0000",
      "dateFinished": "2022-03-20T17:58:54+0000",
      "status": "FINISHED",
      "$$hashKey": "object:198"
    },
    {
      "text": "%md\nAnswer: There are 8 partitions, and no partitioner. map() does not change the number of partitions so it is still the same.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:54+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Answer: There are 8 partitions, and no partitioner. map() does not change the number of partitions so it is still the same.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647738211996_427169840",
      "id": "paragraph_1647738211996_427169840",
      "dateCreated": "2022-03-20T01:03:31+0000",
      "dateStarted": "2022-03-20T17:58:54+0000",
      "dateFinished": "2022-03-20T17:58:54+0000",
      "status": "FINISHED",
      "$$hashKey": "object:199"
    },
    {
      "text": "%spark\nval C = B.groupByKey()\nC.take(20)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:54+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mC\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Iterable[Int])]\u001b[0m = ShuffledRDD[4] at groupByKey at <console>:26\n\u001b[1m\u001b[34mres4\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Iterable[Int])]\u001b[0m = Array((96,CompactBuffer(904, 804, 704, 604, 504, 404, 304, 204, 104, 4)), (56,CompactBuffer(944, 844, 744, 644, 544, 444, 344, 244, 144, 44)), (16,CompactBuffer(984, 884, 784, 684, 584, 484, 384, 284, 184, 84)), (80,CompactBuffer(920, 820, 720, 620, 520, 420, 320, 220, 120, 20)), (48,CompactBuffer(952, 852, 752, 652, 552, 452, 352, 252, 152, 52)), (32,CompactBuffer(968, 868, 768, 668, 568, 468, 368, 268, 168, 68)), (0,CompactBuffer(1000, 900, 800, 700, 600, 500, 400, 300, 200, 100)), (24,CompactBuffer(976, 876, 776, 676, 576, 476, 376, 276, 176, 76)), (64,CompactBuffer(936, 836, 736, 636, 536, 436, 336, 2...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=4",
              "$$hashKey": "object:2578"
            },
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=5",
              "$$hashKey": "object:2579"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_2123592687",
      "id": "20210323-214017_1628283214",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:54+0000",
      "dateFinished": "2022-03-20T17:58:55+0000",
      "status": "FINISHED",
      "$$hashKey": "object:200"
    },
    {
      "text": "%md\nAnswer: There are 8 partitions, and Hash partitioner. groupByKey() triggers a Shuffle and then use a partitioner for efficient grouping. Therefore, we see a Hash partitioner here.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:55+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Answer: There are 8 partitions, and Hash partitioner. groupByKey() triggers a Shuffle and then use a partitioner for efficient grouping. Therefore, we see a Hash partitioner here.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647738214708_2018012124",
      "id": "paragraph_1647738214708_2018012124",
      "dateCreated": "2022-03-20T01:03:34+0000",
      "dateStarted": "2022-03-20T17:58:55+0000",
      "dateFinished": "2022-03-20T17:58:55+0000",
      "status": "FINISHED",
      "$$hashKey": "object:201"
    },
    {
      "text": "%spark\nimport org.apache.spark.HashPartitioner\nval D = B.partitionBy(new HashPartitioner(2))\nD.take(20)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:55+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.HashPartitioner\n\u001b[1m\u001b[34mD\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Int)]\u001b[0m = ShuffledRDD[5] at partitionBy at <console>:27\n\u001b[1m\u001b[34mres5\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Int)]\u001b[0m = Array((0,1000), (2,998), (4,996), (6,994), (8,992), (10,990), (12,988), (14,986), (16,984), (18,982), (20,980), (22,978), (24,976), (26,974), (28,972), (30,970), (32,968), (34,966), (36,964), (38,962))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=6",
              "$$hashKey": "object:2669"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_69893616",
      "id": "20210323-214017_1339820103",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:55+0000",
      "dateFinished": "2022-03-20T17:58:55+0000",
      "status": "FINISHED",
      "$$hashKey": "object:202"
    },
    {
      "text": "%md\nAnswer: There are 2 partitions, and a Hash partitioner. We assign D with a Hash partitioner and 2 partitions as argument. So, that's how we get this result.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:55+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Answer: There are 2 partitions, and a Hash partitioner. We assign D with a Hash partitioner and 2 partitions as argument. So, that&rsquo;s how we get this result.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647738218452_907331030",
      "id": "paragraph_1647738218452_907331030",
      "dateCreated": "2022-03-20T01:03:38+0000",
      "dateStarted": "2022-03-20T17:58:55+0000",
      "dateFinished": "2022-03-20T17:58:55+0000",
      "status": "FINISHED",
      "$$hashKey": "object:203"
    },
    {
      "text": "%spark\nval E = D.groupByKey()\nE.take(20)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:55+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mE\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Iterable[Int])]\u001b[0m = MapPartitionsRDD[6] at groupByKey at <console>:27\n\u001b[1m\u001b[34mres6\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Iterable[Int])]\u001b[0m = Array((34,CompactBuffer(966, 866, 766, 666, 566, 466, 366, 266, 166, 66)), (52,CompactBuffer(948, 848, 748, 648, 548, 448, 348, 248, 148, 48)), (96,CompactBuffer(904, 804, 704, 604, 504, 404, 304, 204, 104, 4)), (4,CompactBuffer(996, 896, 796, 696, 596, 496, 396, 296, 196, 96)), (16,CompactBuffer(984, 884, 784, 684, 584, 484, 384, 284, 184, 84)), (82,CompactBuffer(918, 818, 718, 618, 518, 418, 318, 218, 118, 18)), (66,CompactBuffer(934, 834, 734, 634, 534, 434, 334, 234, 134, 34)), (28,CompactBuffer(972, 872, 772, 672, 572, 472, 372, 272, 172, 72)), (54,CompactBuffer(946, 846, 746, 646, 546, 446, 346...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=7",
              "$$hashKey": "object:2755"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_1963943854",
      "id": "paragraph_1631198002576_655744250",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:55+0000",
      "dateFinished": "2022-03-20T17:58:55+0000",
      "status": "FINISHED",
      "$$hashKey": "object:204"
    },
    {
      "text": "%spark\n//E.partitions.length\nE.partitioner",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:55+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres7\u001b[0m: \u001b[1m\u001b[32mOption[org.apache.spark.Partitioner]\u001b[0m = Some(org.apache.spark.HashPartitioner@2)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647738509325_802065074",
      "id": "paragraph_1647738509325_802065074",
      "dateCreated": "2022-03-20T01:08:29+0000",
      "dateStarted": "2022-03-20T17:58:55+0000",
      "dateFinished": "2022-03-20T17:58:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:205"
    },
    {
      "text": "%md\nAnswer:There are 2 partitions, and a Hash partitioner. groupByKey() is an operation that guarantees the output distribution. Hence, it will carry over the partitioner.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:56+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Answer:There are 2 partitions, and a Hash partitioner. groupByKey() is an operation that guarantees the output distribution. Hence, it will carry over the partitioner.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647738222052_1498903318",
      "id": "paragraph_1647738222052_1498903318",
      "dateCreated": "2022-03-20T01:03:42+0000",
      "dateStarted": "2022-03-20T17:58:56+0000",
      "dateFinished": "2022-03-20T17:58:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:206"
    },
    {
      "text": "%md\nb. Why does the `take()` of D retrieve different pairs than B?\nc. Explain why the keys are no longer in order in the `take()` of C and E.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:56+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>b. Why does the <code>take()</code> of D retrieve different pairs than B?<br />\nc. Explain why the keys are no longer in order in the <code>take()</code> of C and E.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_541652154",
      "id": "paragraph_1638909440005_1799348093",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:56+0000",
      "dateFinished": "2022-03-20T17:58:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:207"
    },
    {
      "text": "%md\nb. The difference is due to D using Has partitioner. D partitions data into two partitions; hence will lead to one partition has odd and the other has even keys. B does not use partitioner.\nc. groupByKey() shuffles the data; hence, the keys are no longer in order",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:56+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>b. The difference is due to D using Has partitioner. D partitions data into two partitions; hence will lead to one partition has odd and the other has even keys. B does not use partitioner.<br />\nc. groupByKey() shuffles the data; hence, the keys are no longer in order</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647739464157_844380784",
      "id": "paragraph_1647739464157_844380784",
      "dateCreated": "2022-03-20T01:24:24+0000",
      "dateStarted": "2022-03-20T17:58:56+0000",
      "dateFinished": "2022-03-20T17:58:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:208"
    },
    {
      "text": "%md\n## Exercise 2.2\nFor each value, write down the number of partitions, whether there is a partitioner assigned to and if so, which one. Also, briefly indicate how you got the answer.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:56+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Exercise 2.2</h2>\n<p>For each value, write down the number of partitions, whether there is a partitioner assigned to and if so, which one. Also, briefly indicate how you got the answer.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342897_1268547461",
      "id": "paragraph_1631202698099_1838796185",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:56+0000",
      "dateFinished": "2022-03-20T17:58:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:209"
    },
    {
      "text": "%spark\nval F = C.map( {case(x,y) => (x, y.reduce((a,b) => a + b))} )\nF.take(20)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:56+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Int)]\u001b[0m = MapPartitionsRDD[7] at map at <console>:27\n\u001b[1m\u001b[34mres8\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Int)]\u001b[0m = Array((96,4540), (56,4940), (16,5340), (80,4700), (48,5020), (32,5180), (0,5500), (24,5260), (64,4860), (40,5100), (72,4780), (8,5420), (88,4620), (41,5090), (81,4690), (97,4530), (25,5250), (65,4850), (73,4770), (57,4930))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=8",
              "$$hashKey": "object:3001"
            },
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=9",
              "$$hashKey": "object:3002"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_2027403572",
      "id": "20210323-214017_546452301",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:56+0000",
      "dateFinished": "2022-03-20T17:58:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:210"
    },
    {
      "text": "%md\nAnswer: There are 8 partitions and no partitioner. map() does not carry over the partitioner of C. The number of partitions is the same as C.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T18:32:54+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647799205647_1831355902",
      "id": "paragraph_1647799205647_1831355902",
      "dateCreated": "2022-03-20T18:00:05+0000",
      "status": "READY",
      "$$hashKey": "object:211"
    },
    {
      "text": "%spark\nval G = C.mapValues( y => y.reduce((a,b) => a + b))\nG.take(10)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:57+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mG\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Int)]\u001b[0m = MapPartitionsRDD[8] at mapValues at <console>:27\n\u001b[1m\u001b[34mres10\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Int)]\u001b[0m = Array((96,4540), (56,4940), (16,5340), (80,4700), (48,5020), (32,5180), (0,5500), (24,5260), (64,4860), (40,5100))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=10",
              "$$hashKey": "object:3092"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_1686805134",
      "id": "paragraph_1638908693622_1541707331",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:57+0000",
      "dateFinished": "2022-03-20T17:58:57+0000",
      "status": "FINISHED",
      "$$hashKey": "object:212"
    },
    {
      "text": "%md\nAnswer: There are 8 partitions and Hash partitioner. mapValues() guarantees that each tuple key remains the same; hence, C partitioner will be carried over. The number of partitions is the same as C",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T18:32:43+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647799266478_342804143",
      "id": "paragraph_1647799266478_342804143",
      "dateCreated": "2022-03-20T18:01:06+0000",
      "status": "READY",
      "$$hashKey": "object:213"
    },
    {
      "text": "%md\n## Exercise 2.3\na. Look up documentation of `repartition()` and `coalesce()` to find out what each of the functions does. Describe the differences. \nb. Take a look at the [Spark UI](http://localhost:4040) (after executing the cells below). Explain why the `takeSample()` of value I requires one shuffle phase less than H. ",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:57+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Exercise 2.3</h2>\n<p>a. Look up documentation of <code>repartition()</code> and <code>coalesce()</code> to find out what each of the functions does. Describe the differences.<br />\nb. Take a look at the <a href=\"http://localhost:4040\">Spark UI</a> (after executing the cells below). Explain why the <code>takeSample()</code> of value I requires one shuffle phase less than H.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_898058497",
      "id": "paragraph_1631197533979_69515493",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:57+0000",
      "dateFinished": "2022-03-20T17:58:57+0000",
      "status": "FINISHED",
      "$$hashKey": "object:214"
    },
    {
      "text": "%md\na. repartition() is used to increase or decrease partitions, coalesce() is used to only decrease the number of partitions in an efficient way. Coalesce() will avoid a full shuffle, which means it can keep data on a minimum number of nodes, then move data from extra nodes to them. In the end, coalesce will result into a narrow dependency. repartition() results in roughly eqqual size partitions.\nb. First, new partitions were created, there was a full shuffle to move all current datat to new partitions. Then, the data needs to be shuffled again to ensure that data is distributed evenly across partitions.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:21:40+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647801512651_846107320",
      "id": "paragraph_1647801512651_846107320",
      "dateCreated": "2022-03-20T18:38:32+0000",
      "status": "READY",
      "$$hashKey": "object:215"
    },
    {
      "text": "%spark\nval H = G.repartition(4)\nH.takeSample(true, 10)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:01:53+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mH\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Int)]\u001b[0m = MapPartitionsRDD[19] at repartition at <console>:29\n\u001b[1m\u001b[34mres22\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Int)]\u001b[0m = Array((77,4730), (55,4950), (21,5290), (30,5200), (91,4590), (15,5350), (67,4830), (21,5290), (19,5310), (27,5230))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=15",
              "$$hashKey": "object:3258"
            },
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=16",
              "$$hashKey": "object:3259"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_1763138517",
      "id": "20210323-214017_1632643197",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:01:53+0000",
      "dateFinished": "2022-03-20T19:01:54+0000",
      "status": "FINISHED",
      "$$hashKey": "object:216"
    },
    {
      "text": "%spark\nH.toDebugString",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:02:21+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres23\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m =\n(4) MapPartitionsRDD[19] at repartition at <console>:29 []\n |  CoalescedRDD[18] at repartition at <console>:29 []\n |  ShuffledRDD[17] at repartition at <console>:29 []\n +-(8) MapPartitionsRDD[16] at repartition at <console>:29 []\n    |  MapPartitionsRDD[8] at mapValues at <console>:27 []\n    |  ShuffledRDD[4] at groupByKey at <console>:26 []\n    +-(8) MapPartitionsRDD[3] at map at <console>:26 []\n       |  ParallelCollectionRDD[2] at parallelize at <console>:26 []\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_44671418",
      "id": "paragraph_1631199440086_136732456",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:02:21+0000",
      "dateFinished": "2022-03-20T19:02:21+0000",
      "status": "FINISHED",
      "$$hashKey": "object:217"
    },
    {
      "text": "%spark\nval I = G.coalesce(4)\nI.takeSample(true, 10)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:07:00+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionSupport": true,
          "completionKey": "TAB"
        },
        "editorMode": "ace/mode/scala",
        "colWidth": 12,
        "editorHide": false,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mI\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, Int)]\u001b[0m = CoalescedRDD[21] at coalesce at <console>:29\n\u001b[1m\u001b[34mres24\u001b[0m: \u001b[1m\u001b[32mArray[(Int, Int)]\u001b[0m = Array((72,4780), (70,4800), (93,4570), (99,4510), (8,5420), (14,5360), (37,5130), (6,5440), (34,5160), (79,4710))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=17",
              "$$hashKey": "object:3349"
            },
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=18",
              "$$hashKey": "object:3350"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_935340498",
      "id": "20210323-214017_1102115685",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:07:00+0000",
      "dateFinished": "2022-03-20T19:07:00+0000",
      "status": "FINISHED",
      "$$hashKey": "object:218"
    },
    {
      "text": "%spark\nI.toDebugString",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:07:02+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres25\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m =\n(4) CoalescedRDD[21] at coalesce at <console>:29 []\n |  MapPartitionsRDD[8] at mapValues at <console>:27 []\n |  ShuffledRDD[4] at groupByKey at <console>:26 []\n +-(8) MapPartitionsRDD[3] at map at <console>:26 []\n    |  ParallelCollectionRDD[2] at parallelize at <console>:26 []\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_145690826",
      "id": "paragraph_1631199441170_1752903184",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:07:02+0000",
      "dateFinished": "2022-03-20T19:07:02+0000",
      "status": "FINISHED",
      "$$hashKey": "object:219"
    },
    {
      "text": "%md\n## Exercise 3\nWe return to the Shakespeare data that we already saw in the reader.\na. Create `val lines`. _Hint: this is also done in the reader._",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:58+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Exercise 3</h2>\n<p>We return to the Shakespeare data that we already saw in the reader.<br />\na. Create <code>val lines</code>. <em>Hint: this is also done in the reader.</em></p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_205478966",
      "id": "paragraph_1631794513100_1892205778",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:58+0000",
      "dateFinished": "2022-03-20T17:58:58+0000",
      "status": "FINISHED",
      "$$hashKey": "object:220"
    },
    {
      "text": "%spark\nval lines = sc.textFile(\"file:///opt/hadoop/100.txt\")",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:41:40+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mlines\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[String]\u001b[0m = file:///opt/hadoop/100.txt MapPartitionsRDD[3] at textFile at <console>:26\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_733808240",
      "id": "paragraph_1644578339988_247896699",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:41:40+0000",
      "dateFinished": "2022-03-20T19:41:40+0000",
      "status": "FINISHED",
      "$$hashKey": "object:221"
    },
    {
      "text": "%md\nb. Find the length of the longest sentence in the corpus using the Map Reduce pattern, knowing that in scala you can write `4 max 6` to get 6 as their maximum. _Hint: look at the map-reduce of counting chars in the reader._",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:58+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>b. Find the length of the longest sentence in the corpus using the Map Reduce pattern, knowing that in scala you can write <code>4 max 6</code> to get 6 as their maximum. <em>Hint: look at the map-reduce of counting chars in the reader.</em></p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_571490476",
      "id": "paragraph_1631794514388_1658014158",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:58+0000",
      "dateFinished": "2022-03-20T17:58:58+0000",
      "status": "FINISHED",
      "$$hashKey": "object:222"
    },
    {
      "text": "%spark\n// Empty cell for b\nlines.map(s => s.length).max()",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:41:42+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres2\u001b[0m: \u001b[1m\u001b[32mInt\u001b[0m = 78\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=0",
              "$$hashKey": "object:5108"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_2082945536",
      "id": "paragraph_1631794516065_1023514008",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:41:42+0000",
      "dateFinished": "2022-03-20T19:41:43+0000",
      "status": "FINISHED",
      "$$hashKey": "object:223"
    },
    {
      "text": "%md \nLet's run a word count on Shakespeare again by executing the cells below. ",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T17:58:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Let&rsquo;s run a word count on Shakespeare again by executing the cells below.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_1327945032",
      "id": "paragraph_1631794516979_1634986002",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T17:58:59+0000",
      "dateFinished": "2022-03-20T17:58:59+0000",
      "status": "FINISHED",
      "$$hashKey": "object:224"
    },
    {
      "text": "%spark\nval words = lines.flatMap(line => line.split(\" \"))\n              .filter(_ != \"\")\n              .map(word => (word,1))\n              .reduceByKey(_ + _)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:41:45+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mwords\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(String, Int)]\u001b[0m = ShuffledRDD[8] at reduceByKey at <console>:29\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_1961733518",
      "id": "paragraph_1638293827329_547083269",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:41:45+0000",
      "dateFinished": "2022-03-20T19:41:46+0000",
      "status": "FINISHED",
      "$$hashKey": "object:225"
    },
    {
      "text": "%spark\nwords.take(10)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:41:50+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres3\u001b[0m: \u001b[1m\u001b[32mArray[(String, Int)]\u001b[0m = Array((hack'd.,1), (durst,,2), (Ah!,6), (Worthy;,1), (bone,6), (vailing,1), (bombast,1), (person-,1), (LAFEU],1), (fiction.,1))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=1",
              "$$hashKey": "object:5173"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_551858248",
      "id": "paragraph_1639513911785_688468669",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:41:50+0000",
      "dateFinished": "2022-03-20T19:41:51+0000",
      "status": "FINISHED",
      "$$hashKey": "object:226"
    },
    {
      "text": "%spark\nwords.filter(_._1 == \"Julia\").collect\n  .map({case (w,c) => \"%s occurs %d times\".format(w,c)}).map(println)",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:41:54+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Julia occurs 12 times\n\u001b[1m\u001b[34mres4\u001b[0m: \u001b[1m\u001b[32mArray[Unit]\u001b[0m = Array(())\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=2",
              "$$hashKey": "object:5216"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_938410143",
      "id": "paragraph_1631794611208_458640180",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:41:54+0000",
      "dateFinished": "2022-03-20T19:41:55+0000",
      "status": "FINISHED",
      "$$hashKey": "object:227"
    },
    {
      "text": "%md\nIn the reader, the count for “Julia” was 145. \nc. Why are the counts different now, and give examples of words that are not count.",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>In the reader, the count for “Julia” was 145.<br />\nc. Why are the counts different now, and give examples of words that are not count.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_242935066",
      "id": "paragraph_1639513427120_40116472",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:228"
    },
    {
      "text": "%md\nFirst, we didn't remove special characters like \"'s\" or \"`\", so there are words like \"Julia's\" or \"Julia!\". Secondly, we also did not account for case-sensitive, there are words like \"JULIA\" or \"julia\" in the corpus.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:31:44+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647804524253_1755191156",
      "id": "paragraph_1647804524253_1755191156",
      "dateCreated": "2022-03-20T19:28:44+0000",
      "status": "READY",
      "$$hashKey": "object:229"
    },
    {
      "text": "%md\nNow we want to store the result of `words` to a textfile in the filesystem. \nd. Search for the correct function in the [RDD programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html) and use `file:///opt/hadoop/wc` as location.",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Now we want to store the result of <code>words</code> to a textfile in the filesystem.<br />\nd. Search for the correct function in the <a href=\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\">RDD programming guide</a> and use <code>file:///opt/hadoop/wc</code> as location.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_1021715573",
      "id": "paragraph_1631794640182_1479472893",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:230"
    },
    {
      "text": "%spark\n// Empty cell for d\nwords.saveAsTextFile(\"file:///opt/hadoop/wc\")",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:37:17+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://1ab39313137f:4040/jobs/job?id=23",
              "$$hashKey": "object:3898"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_2146788273",
      "id": "paragraph_1631794642824_582481467",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:37:17+0000",
      "dateFinished": "2022-03-20T19:37:18+0000",
      "status": "FINISHED",
      "$$hashKey": "object:231"
    },
    {
      "text": "%md\nWe can use a simple shell command to look into the directory that has been created.",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>We can use a simple shell command to look into the directory that has been created.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342898_1822575215",
      "id": "paragraph_1631794654282_2074133671",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:232"
    },
    {
      "text": "%sh\nls -al /opt/hadoop/wc",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:39:05+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "total 964\ndrwxr-xr-x. 1 hadoop hadoop    142 Mar 20 19:37 .\ndrwx------. 1 hadoop hadoop    158 Mar 20 19:37 ..\n-rw-r--r--. 1 hadoop hadoop      8 Mar 20 19:37 ._SUCCESS.crc\n-rw-r--r--. 1 hadoop hadoop   3792 Mar 20 19:37 .part-00000.crc\n-rw-r--r--. 1 hadoop hadoop   3804 Mar 20 19:37 .part-00001.crc\n-rw-r--r--. 1 hadoop hadoop      0 Mar 20 19:37 _SUCCESS\n-rw-r--r--. 1 hadoop hadoop 484301 Mar 20 19:37 part-00000\n-rw-r--r--. 1 hadoop hadoop 485394 Mar 20 19:37 part-00001\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342899_2050520319",
      "id": "paragraph_1631794667893_1654848878",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "dateStarted": "2022-03-20T19:39:05+0000",
      "dateFinished": "2022-03-20T19:39:06+0000",
      "status": "FINISHED",
      "$$hashKey": "object:233"
    },
    {
      "text": "%md\n\nHowever, we can also look at it directly from your terminal. Issue the command `docker exec -it hey-spark /bin/bash` in a terminal on the machine running the notebook container and navigate to the same folder as above.",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>However, we can also look at it directly from your terminal. Issue the command <code>docker exec -it hey-spark /bin/bash</code> in a terminal on the machine running the notebook container and navigate to the same folder as above.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342899_1535440640",
      "id": "paragraph_1639514412539_1659579788",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:234"
    },
    {
      "text": "%md\nf. Inspect the files. How many and why are there multiple result files?",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>f. Inspect the files. How many and why are there multiple result files?</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342899_1307723926",
      "id": "paragraph_1631794679101_712928786",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:235"
    },
    {
      "text": "%md\nThere are 6 files. There were two partitions so each partition result was written into a different result file.",
      "user": "anonymous",
      "dateUpdated": "2022-03-20T19:43:11+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647805235171_1627514553",
      "id": "paragraph_1647805235171_1627514553",
      "dateCreated": "2022-03-20T19:40:35+0000",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:4918"
    },
    {
      "text": "%md\ng. (optional/advanced) Complete freedom! Do whatever you want with the Shakespeare data. Do some different word counts, other filters, etc. \n\nIf you want to store another textfile to the file system, make sure to use another name than `wc`. Files are not automatically overwritten. \nYou can also clean up and delete the old directory, for this you can use the command below (for another file: change file name accordingly).",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>g. (optional/advanced) Complete freedom! Do whatever you want with the Shakespeare data. Do some different word counts, other filters, etc.</p>\n<p>If you want to store another textfile to the file system, make sure to use another name than <code>wc</code>. Files are not automatically overwritten.<br />\nYou can also clean up and delete the old directory, for this you can use the command below (for another file: change file name accordingly).</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342899_1813028804",
      "id": "paragraph_1631794707296_339287076",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:236"
    },
    {
      "text": "%sh\nrm -rf /opt/hadoop/wc",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342899_147242970",
      "id": "paragraph_1631794717982_1676534120",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:237"
    },
    {
      "text": "%md\n## Wrap up\n\nIf you have reached this point properly and understood what you observed, you have a solid understanding of Spark and its execution model. \n\nExport your Exercises notebook by clicking `Export this note (zpln)` in the toolbar (do not export it as IPython, because it can mess up the cells) and submit your Zeppelin Notebook to the assignment box on Brightspace. After that, you can do the quiz to check your answers. If you have any questions left after that, do not hesistate and come to the lab sessions to discuss your assignment (or ask your question online in the matrix room).",
      "user": "anonymous",
      "dateUpdated": "2022-03-11T18:12:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "colWidth": 12,
        "editorHide": true,
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Wrap up</h2>\n<p>If you have reached this point properly and understood what you observed, you have a solid understanding of Spark and its execution model.</p>\n<p>Export your Exercises notebook by clicking <code>Export this note (zpln)</code> in the toolbar (do not export it as IPython, because it can mess up the cells) and submit your Zeppelin Notebook to the assignment box on Brightspace. After that, you can do the quiz to check your answers. If you have any questions left after that, do not hesistate and come to the lab sessions to discuss your assignment (or ask your question online in the matrix room).</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1647022342899_955998751",
      "id": "20210323-214017_672918386",
      "dateCreated": "2022-03-11T18:12:22+0000",
      "status": "READY",
      "$$hashKey": "object:238"
    }
  ],
  "name": "A3_Exercises",
  "id": "2GWYZ4FEW",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/A3_Exercises"
}